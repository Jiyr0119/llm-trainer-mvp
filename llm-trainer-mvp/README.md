# 大语言模型训练平台 MVP

这是一个可在本地运行的简化版大语言模型训练平台MVP，展示了核心功能流程。

## 功能特性

1. 数据集上传与管理
2. 基于BERT的文本分类模型训练
3. 模型推理演示
4. Web界面操作

## 环境要求

- Python 3.9+
- Node.js 16+
- 至少8GB内存

## 安装步骤

1. 克隆项目或复制代码到本地目录

2. 安装后端依赖：
```bash
cd backend
pip install -r requirements.txt
```

3. 安装前端依赖：
```bash
cd frontend
npm install
```

## 运行步骤

1. 启动后端服务：
```bash
cd backend
python main.py
```

2. 启动前端服务（新终端窗口）：
```bash
cd frontend
npm run dev
```

3. 打开浏览器访问：http://localhost:5173

## 使用说明

1. 首先在"数据上传"页面上传CSV格式的数据集（包含text和label列）
2. 在"模型训练"页面选择数据集并开始训练
3. 训练完成后，在"模型推理"页面测试模型效果

## 注意事项

- 此MVP版本仅用于演示核心功能流程
- 在生产环境中需要更多优化和安全措施
- 训练时间和资源消耗取决于数据集大小和硬件配置

## AI 对话功能

新增 AI 对话模块，提供类似 Gemini 的现代化交互体验：

- **多模型支持**：支持切换不同的本地 LLM 模型 (如 Qwen, Llama2 等)。
- **流式响应**：实时打字机效果，沉浸式对话体验。
- **历史记录**：自动保存对话历史，支持重命名和删除。
- **快捷指令**：提供常用 prompt 快捷方式。

### 开启对话
1. 确保后端 `backend/app` 下已配置模型（或使用默认 Mock 模式）。
2. 在前端导航栏点击 "AI Chat" 进入。